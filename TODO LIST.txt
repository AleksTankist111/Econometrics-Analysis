*) Исправить метод выбора длины обучающей выборки

+0) Исправить баг, когда при смещении семпла от нуля, реальные данные
	не добираются до минимума, в результате чего иногда не работает
	игра. Иногда еще замечено смещение реального ответа от предикта.
	+-### ДЛЯ ИСПРАВЛЕНИЯ БАГА №0.1 НУЖНО ЗАФИТИТЬ ДАННЫЕ--- РЕГУЛЯРИЗАЦИЯ
				И еще наверное поставить область, с которой можно класть депозит
				(но как ее определять?)

+1) Разделить draw_line отдельно на счет и на рисование. 
	Применять "stop\start" Только к рисованию.

2) Центрировать график на семпл, игнорируя признаки   (а нужно ли? признаки всё равно временные)

3)     + Реализовать playing в новой версии
	СТОИТ ЕЩЕ ПОИГРАТЬСЯ С ПРОИЗВОДНЫМИ (и вторыми) ПРИ ВЫБОРЕ ТОЧКИ ВКЛАДА (и ВЫВОДА)
        УСТАНОВИТЬ ПРЕДЕЛ ОЖИДАНИЯ ПРОДАЖИ
        УСТАНОВИТЬ ПРЕДЕЛ ПОТЕРЬ

+4) Заполнить axs[1] Скелетоном, axs[2] текущим фурье-спектром.

+5) Добавить новую axes с ошибками предсказания для каждого используемого
	метода ML. 

6) Изменить методику предсказания - вместо одной точки сделать
	распределение вероятностей: (P(current_point +3);+2;+1;+0;-1;...) 

7) Добавить новые методы предсказания (возможно, переделать старый):
	а) MLP
	b) Linear Regr +
	c) Polinomial regr
	d) SVM     

	(a,b,c,d - ???)
	
	Для всех выше: 
		I) Проверить на 4 базовых фичах
		II) Проверить на предыдущих состояниях семпла
		III) Сравнить основу Скелетона с базовыми фичами 
			(t-test? covariance?) 
		IV) Опробовать несколько задержек (варьировать delay)


8) Опробовать на реальных данных

9) Реализовать парсинг для in-real-time обновления данных

10) Сделать Блок-плот на каждом этапе предсказания\или разделение с колорбаром по вероятностям в
	областях "+3;+2;+1...."

11) вставить алгоритм нахождения наиболее значимой задержки для каждого из каналов. (то что с Юле учил)

12) Разбить программу на модули по ролям



----------------------

РАССМОТРЕНИЕ ЗНАЧИМЫХ ЗАДЕРЖЕК И ИГРА ЧЕРЕЗ РЕГРЕССИЮ:

+ 1) Сделать предсказания на несколько шагов вперед (с использованием ранее предсказанных результатов)?

+ 2) Использовать новый способ создания тестовых данных (нормальное распределение от предыдущего шага).

+ 3) В связи с (2), ввести в "признаки" сам массив результатов, чтобы проверить зависимости. Сделать что-то с 0-элементом (т.к. этот признак равен текущему семплу)
	NOTE: Сделать можно уже в самом коде, просто создав массив "признаков" на предыдущий элемент от текущего. И проверить его. 


+ 4) в Train-test-split добавить bool параметр "equal" : Если True, то Тренировочная выборка будет с равным числом классов.     

+- 5) Сделать MSE в том же месте, где и регрессоры (в том же модуле) - необходимо для кросс-валидационной проверки
		NOTE: Были использованы уже готовые модули для регрессии - sklearn		

+ 6) Сделать отдельный модуль для построения тестовых выборок. Реализовать с использованием классов (Чтоб выдавался объект с аргументами и функциями)

7) Сделать отдельный модуль, в котором объединятся все MLA - просто файл с import ... каждого из ml алгоритмов, реализованных отдельно.

8) Сделать класс для работы с классификатором? 

+ 9) Сделать проверку признаков на автоковариацию - сделать PCA всех признаков! (добавить в cov_proc). Рассмотреть варианты с нескореллированными значениям.

+ 10) В CP создать функцию, которая по border и difs_list возвращает список difs, где в каждом канале
	остались только значения больше borders.

+ 11) Используя 10, реализовать цикл отбрасывания мелких временных задержек - предварительное
	изменение размерности. После этого делать PCA, и потом на этом обучать регрессор.
	Также в каждой итерации можно использовать функцию deep_prediction, для вычисления ошибки
	дальних предсказаний. Очевидно, каждая итерация будет давать набор MSE на один длиннее предыдущего.
	
	Вывести все MSE на экран. Дальше будем думать

12) Сделать проверку стационарности

13) Сделать PACF!

	
 